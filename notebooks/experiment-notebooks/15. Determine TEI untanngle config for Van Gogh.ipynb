{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e28cb8",
   "metadata": {},
   "source": [
    "Doe een SAX-style parse van een TEI document(-set) en bepaal alle unieke patronen van relevante inputwaarden voor untanngle. Relevant in de zin van 'hiermee moet kunnen worden bepaald welke handlercode dit SAX-event moet triggeren'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45cfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../packages')\n",
    "\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import tei.util as tei\n",
    "\n",
    "path = '../../data/vangogh/let*.xml'\n",
    "datadir = '../../data/output/'\n",
    "\n",
    "tei_namespace = '{http://www.tei-c.org/ns/1.0}'\n",
    "vangogh_namespace = '{http://www.vangoghletters.org/ns/}'\n",
    "\n",
    "def get_file_sequence_for_dir(path):\n",
    "    tei_file_names = (f for f in glob.glob(path))\n",
    "    return sorted(tei_file_names)\n",
    "\n",
    "tei_file_names = get_file_sequence_for_dir(path)\n",
    "unique_results = tei.find_unique_contexts(tei_file_names)\n",
    "print(f\"There are {len(unique_results)} unique (tag,parent,parent-attr-key) tuples:\")\n",
    "pprint(unique_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c73ae9",
   "metadata": {},
   "source": [
    "Hierboven heb ik alle unieke typen events gevonden, en daar allereerst 'ab' (anonymous block) event typen uitgefilterd. 'ab' komt dus voor binnen div's met een 'type' attribuut en binnen notes (met attributes n, id en target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de836d9f",
   "metadata": {},
   "source": [
    "Volgende stap: vul deze 'records' handmatig aan met benodigde info voor verdere untanngling, inclusief de namen van handler-functies.\n",
    "Extra info: elt_type (text_container, milestone, ..., wellicht al vastgelegd door koppeling aan handler), resource_id, annotation_type (label, is eigenlijk 'tag'), custom_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "_last_begin_indexes = {}\n",
    "_last_end_indexes = {}\n",
    "\n",
    "def text_handler(event, type, action, resource_id, parent, text_segments, annotations):\n",
    "    print('called text_handler with:')\n",
    "    print(f\"type: {type}\\naction: {action}\\nresource_id: {resource_id}\\nparent: {parent}\")\n",
    "    \n",
    "    global _last_begin_indexes\n",
    "    global _last_end_indexes    \n",
    "        \n",
    "    if action == 'start':\n",
    "        _last_begin_indexes[type] = text_segments.len()\n",
    "    if action == 'end':\n",
    "        parts = [];\n",
    "        # leaf text element, add to all_textelements, also include text after possible pb's\n",
    "        for _, part in enumerate(event.itertext()):\n",
    "            parts.append(part.strip())\n",
    "        line = ' '.join(parts)\n",
    "        print(f\"line: [{line}]\")\n",
    "        text_segments.append(line)\n",
    "            \n",
    "        _last_end_indexes[type] = text_segments.len()-1\n",
    "        annotations.append({'resource_id': resource_id, 'label':type, \n",
    "                            'begin_anchor': text_segments._anchors[_last_begin_indexes[type]],\\\n",
    "                            'end_anchor':text_segments._anchors[_last_end_indexes[type]],\n",
    "                            'id': 'annot_'+str(uuid.uuid4())}) \n",
    "    return\n",
    "\n",
    "def annotate_parent_handler(event, type, action, resource_id, parent, text, annotations):\n",
    "    print('called annotate_parent_handler with:')\n",
    "#    print(f\"type: {type}\\naction: {action}\\nresource_id: {resource_id}\\nparent: {parent}\")\n",
    "    \n",
    "    return\n",
    "\n",
    "handler_dispatcher = [\n",
    "    {\n",
    "        'condition':{\n",
    "            'element': 'parent',\n",
    "            'attribute': 'type',\n",
    "            'value': 'original'\n",
    "        },\n",
    "        'handler': text_handler\n",
    "    },\n",
    "    {\n",
    "        'condition': {\n",
    "            'element': 'parent',\n",
    "            'attribute': 'type',\n",
    "            'value': 'translation'            \n",
    "        },\n",
    "        'handler': annotate_parent_handler        \n",
    "    }\n",
    "]\n",
    "\n",
    "handler_dispatcher_p = [\n",
    "    {\n",
    "        'condition':{\n",
    "            'element': 'parent',\n",
    "            'xml_tag': 'note',\n",
    "        },\n",
    "        'handler': text_handler\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fcaa17",
   "metadata": {},
   "source": [
    "select records and associate them with the handler_dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [rec for rec in unique_results if rec['tag'] == '{http://www.tei-c.org/ns/1.0}ab']\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[0]['handler_dispatcher'] = handler_dispatcher\n",
    "#filtered[0]['condition'] = {\n",
    "#                'element': 'parent',\n",
    "#                'attribute': 'type',\n",
    "#                'value': 'original'\n",
    "#            }\n",
    "#filtered[0]['handler'] = text_handler\n",
    "\n",
    "# deze gaat vooralsnog niets doen, want conditions gaan niet matchen\n",
    "filtered[1]['handler_dispatcher'] = handler_dispatcher\n",
    "\n",
    "filtered[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df144a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [rec for rec in unique_results if rec['tag'] == '{http://www.tei-c.org/ns/1.0}p']\n",
    "filtered[2]['handler_dispatcher'] = handler_dispatcher_p\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9784f",
   "metadata": {},
   "source": [
    "Vraag is nu, of deze subset van unique_results voldoende info bevat om het untanngle-proces te sturen. Volgende stap is dus kijken in hoeverre ik de oude untanngle code voor TEI hieraan kan aanpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d628ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textservice import segmentedtext\n",
    "\n",
    "_last_page_begin_index = 0\n",
    "_last_section_begin_index = -1\n",
    "_last_chapter_begin_index = -1\n",
    "_last_paragraph_begin_index = -1\n",
    "_last_head_begin_index = -1\n",
    "\n",
    "_last_page_end_index = -1\n",
    "_last_section_end_index = -1\n",
    "_last_chapter_end_index = -1\n",
    "_last_paragraph_end_index = -1\n",
    "_last_head_end_index = -1\n",
    "\n",
    "_last_page_id = \"\"\n",
    "\n",
    "def get_input_pattern_from(action, elem):\n",
    "    parent_tag = None if elem.getparent() == None else elem.getparent().tag\n",
    "    parent_keys = None if parent_tag == None else elem.getparent().attrib.keys()\n",
    "                \n",
    "    input_pattern = {\n",
    "#        'event': action,\n",
    "        'tag': elem.tag,\n",
    "        'parent': parent_tag,\n",
    "        'parent_attrib_keys': parent_keys,\n",
    "    }  \n",
    "    return input_pattern\n",
    "\n",
    "# handle each of the elements in the hierarchy according to 'layer type'\n",
    "def handle_element(resource_id,action,e,text_segments,annotations): \n",
    "#     global resource_id\n",
    "    global _last_page_begin_index\n",
    "    global _last_section_begin_index\n",
    "    global _last_chapter_begin_index\n",
    "    global _last_head_begin_index\n",
    "\n",
    "    global _last_page_end_index\n",
    "    global _last_section_end_index\n",
    "    global _last_chapter_end_index\n",
    "    global _last_head_end_index\n",
    "    \n",
    "    global _last_page_id\n",
    "    \n",
    "    # determine input_pattern from action and elem\n",
    "    input_pattern = get_input_pattern_from(action, e)\n",
    "    \n",
    "    # find matching patterns in unique_results\n",
    "    for pattern in unique_results:\n",
    "        if all(item in pattern.items() for item in input_pattern.items()):\n",
    "            # find handler function by checking conditions from handler_dispatcher\n",
    "            # handler_dispatcher is a list of condition/handler dicts\n",
    "            if 'handler_dispatcher' in pattern:\n",
    "#            if 'condition' in pattern:\n",
    "                for handler_entry in pattern['handler_dispatcher']:\n",
    "                    element = handler_entry['condition']['element']\n",
    "                    xml_element = None\n",
    "                    if element == 'parent':\n",
    "                        xml_element = e.getparent()\n",
    "                        print(xml_element.tag)\n",
    "                    \n",
    "                    # temporary if's, fix by introducing a class/function that checks a condition\n",
    "                    if 'attribute' in handler_entry['condition']:\n",
    "                        attribute = handler_entry['condition']['attribute']\n",
    "                        value = handler_entry['condition']['value']\n",
    "                \n",
    "                        if attribute in xml_element.attrib and xml_element.attrib[attribute] == value:\n",
    "                            handler_entry['handler'](e, pattern['tag'], action, resource_id, \\\n",
    "                                                 xml_element, text_segments, annotations)\n",
    "                    if 'xml_tag' in handler_entry['condition']:\n",
    "                        element_tag = handler_entry['condition']['xml_tag']\n",
    "                        print(f\"value from condition: {tei_namespace+element_tag}, parent tag: {xml_element.tag}\")\n",
    "                        if tei_namespace+element_tag == xml_element.tag:\n",
    "                            handler_entry['handler'](e, pattern['tag'], action, resource_id, \\\n",
    "                                                 xml_element, text_segments, annotations)\n",
    "    return\n",
    "    \n",
    "    if action == 'start':\n",
    "        # store last begin indexes\n",
    "        if e.tag == tei_namespace+'ab':\n",
    "            _last_paragraph_begin_index = text.len()               \n",
    "        elif e.tag == 'div' and e.get('type') == 'chapter':\n",
    "            _last_chapter_begin_index = text.len()\n",
    "        elif e.tag == 'div' and e.get('type') == 'section':\n",
    "            _last_section_begin_index = text.len()\n",
    "        elif e.tag == 'head':\n",
    "            _last_head_begin_index = text.len()\n",
    "    elif action == 'end':\n",
    "        if e.tag == tei_namespace+'ab': \n",
    "            # leaf text element, add to all_textelements, also include text after possible pb's\n",
    "            for index, t in enumerate(e.itertext()):\n",
    "                text.append(t.strip())\n",
    "                if index > 0: # assume: caused by pb contained within p. Update page end.\n",
    "                    _last_page_end_index = text.len()-1\n",
    "            \n",
    "            _last_paragraph_end_index = text.len()-1\n",
    "\n",
    "            if _last_paragraph_begin_index <= _last_paragraph_end_index:\n",
    "                annotations.append({'resource_id': resource_id, 'label':'paragraph','begin_anchor': text_segments._anchors[_last_paragraph_begin_index],\\\n",
    "                            'end_anchor':text_segments._anchors[_last_paragraph_end_index],'id': 'annot_'+str(uuid.uuid4())})\n",
    "        elif e.tag == 'head':\n",
    "            # leaf text element, add to all_textelements\n",
    "            text.append(e.text)\n",
    "            \n",
    "            _last_head_end_index = text.len()-1\n",
    "            annotations.append({'resource_id': resource_id, 'label':'head','begin_anchor': text._anchors[_last_head_begin_index],\\\n",
    "                            'end_anchor':text._anchors[_last_head_end_index],'id': 'annot_'+str(uuid.uuid4())}) \n",
    "        elif e.tag == 'div' and e.get('type') == 'chapter':\n",
    "            _last_chapter_end_index = text.len()-1\n",
    "            annotations.append({'resource_id': resource_id, 'label':'chapter','begin_anchor': text._anchors[_last_chapter_begin_index],\\\n",
    "                            'end_anchor':text._anchors[_last_chapter_end_index],'id': 'annot_'+str(uuid.uuid4())})            \n",
    "        elif e.tag == 'div' and e.get('type') == 'section':\n",
    "            _last_section_end_index = text.len()-1\n",
    "            annotations.append({'resource_id': resource_id, 'label':'section','begin_anchor': text._anchors[_last_section_begin_index],\\\n",
    "                            'end_anchor':text._anchors[_last_section_end_index],'id': 'annot_'+str(uuid.uuid4())})               \n",
    "        elif e.tag == 'pb':\n",
    "            # first store the 'previous' page, then store begin and end of currently closed page\n",
    "            annotations.append({'resource_id': resource_id, 'label':'page','begin_anchor': text._anchors[_last_page_begin_index],\\\n",
    "                            'end_anchor':text._anchors[_last_page_end_index],'id': _last_page_id}) \n",
    "            _last_page_begin_index = _last_page_end_index\n",
    "            _last_page_end_index = text.len()-1 \n",
    "            _last_page_id = f\"page-{e.get('n')}\"\n",
    "#    elif action == 'start-ns':\n",
    "#        print(e[1]) # namespaceURI part of e, in case of a namespace declaration     \n",
    "            \n",
    "    return        \n",
    "\n",
    "def traverse(resource_id,node,text_segments,annotations):\n",
    "    for action, elem in node:\n",
    "        handle_element(resource_id,action,elem,text_segments,annotations)\n",
    "        \n",
    "    return\n",
    "    \n",
    "# Process per file, properly concatenate results, maintaining proper referencing the baseline text elements\n",
    "resource_id = 'let005'\n",
    "all_textelements=segmentedtext.SplittableSegmentedText(resource_id)\n",
    "\n",
    "all_annotations=[]\n",
    "\n",
    "# for f_name in get_file_sequence_for_container(resource_id):\n",
    "for f_name in ['../../data/vangogh/let005.xml']:\n",
    "    text_segments = segmentedtext.SplittableSegmentedText()\n",
    "    annotation_array = []\n",
    "            \n",
    "    source_data = tei.get_root_tree_element(f_name)\n",
    "\n",
    "    traverse(f_name,source_data,text_segments,annotation_array)\n",
    "    \n",
    "    all_textelements.extend(text_segments)       \n",
    "    all_annotations.extend(annotation_array)\n",
    "    \n",
    "    print(all_textelements)\n",
    "    print(annotation_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9342f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
